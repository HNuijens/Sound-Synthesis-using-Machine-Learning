{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdc9721",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size:3rem;color:darkcyan\"> Preprocessing data</h1>\n",
    "to train a variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7232e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db5fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    def __init__(self, \n",
    "                 save_path,\n",
    "                 json_path,\n",
    "                 audio_duration = 0.74,\n",
    "                 min_duration = 0.1,\n",
    "                 n_fft = 512, \n",
    "                 hop_size = 256,\n",
    "                 sample_rate=22050):\n",
    "        \n",
    "        self.dataset_path = save_path\n",
    "        self.json_path = json_path\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_size = hop_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.audio_duration = int(audio_duration * sample_rate)\n",
    "        self.min_duration = int(min_duration * sample_rate)\n",
    "        self.min_max_values = {}\n",
    "        \n",
    "        self.data  = {\n",
    "        'mappings' : [],  # corresponding digit\n",
    "        'labels' : [],    # corresponding number\n",
    "        'log_spectrogram' : [],      # extracted spectrum\n",
    "        'filenames' : [],  # original filenames\n",
    "        'min_max_values' : [] # for denormalizing\n",
    "        }\n",
    "        \n",
    "    def process_dataset(self):\n",
    "        # load data \n",
    "        n_folders = len(os.listdir(self.dataset_path))\n",
    " \n",
    "        for i, (dirpath, dirnames, filenames) in enumerate(os.walk(root)):\n",
    "            if dirpath is not root:\n",
    "                print(f'processing folder {i} out of {n_folders}')\n",
    "\n",
    "                for file in filenames:\n",
    "                    file_path = os.path.join(dirpath + '/' + file)\n",
    "                    \n",
    "                    # load audio\n",
    "                    signal = self._load_audio(file_path)\n",
    "                    \n",
    "                    # ignore unusable audio\n",
    "                    if len(signal) < self.min_duration:\n",
    "                        continue\n",
    "                    \n",
    "                    if len(signal) > self.audio_duration:\n",
    "                        signal = signal[:self.audio_duration]\n",
    "                        \n",
    "                    # zero pad\n",
    "                    if len(signal) < self.audio_duration:\n",
    "                        signal = self._right_pad(signal)\n",
    "\n",
    "                    # normalize\n",
    "                    signal = self._normalize(signal)\n",
    "                    \n",
    "                    # extract log spectrogram\n",
    "                    log_spectrogram = self._extract_log_spectrogram(signal)\n",
    "                    \n",
    "                    # save\n",
    "                    self.data['labels'].append(int(file[0]))\n",
    "                    self.data['log_spectrogram'].append(log_spectrogram.tolist()) \n",
    "                    self.data['filenames'].append(file)\n",
    "                    self.data['min_max_values'].append(np.array(log_spectrogram.min(), log_spectrogram.max()).tolist())\n",
    "            \n",
    "                if i == 1:\n",
    "                    break\n",
    "                \n",
    "        print(f'Saving dataset as {self.json_path}...')                \n",
    "        with open(self.json_path, 'w') as fp:\n",
    "            json.dump(self.data, fp, indent = 4)\n",
    "        print(f'Done saving ') \n",
    "                    \n",
    "    def _load_audio(self, file_path):\n",
    "        signal, _ = librosa.load(file_path,\n",
    "                                 sr = self.sample_rate,\n",
    "                                 mono=True)[:self.audio_duration]\n",
    "        return signal\n",
    "    \n",
    "    def _right_pad(self, signal, mode = 'constant'):\n",
    "        num_missing_samples = self.audio_duration - len(signal)\n",
    "        return np.pad(signal, \n",
    "                      (0, num_missing_samples), \n",
    "                      mode = mode)\n",
    "    \n",
    "    def _left_pad(self, signal, mode = 'constant'):\n",
    "        num_missing_samples = self.audio_duration - len(signal)\n",
    "        return np.pad(signal, \n",
    "                      (num_missing_samples, 0), \n",
    "                      mode = mode)\n",
    "        \n",
    "    def _normalize(self, signal, min_val = 0, max_val = 1):\n",
    "        norm_signal = (signal - signal.min()) / (signal.max() - signal.min())\n",
    "        norm_signal = norm_signal * (max_val - min_val) + min_val\n",
    "        return norm_signal\n",
    "\n",
    "    def _denormalize(self, signal, signal_min, original_max):\n",
    "        signal = (norm_signal - min_val) / (max_val - min_val)\n",
    "        signal = signal * (original_max - original_min) + original_min\n",
    "        return signal\n",
    "        \n",
    "    def _extract_log_spectrogram(self, signal):\n",
    "        stft = librosa.stft(signal,\n",
    "                            n_fft = self.n_fft,\n",
    "                            hop_length = self.hop_size)[:-1]\n",
    "        \n",
    "        spectrogram = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "        return log_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8afa5b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing folder 1 out of 60\n",
      "Saving dataset as data.json...\n",
      "Done saving \n"
     ]
    }
   ],
   "source": [
    "root = '../../../Datasets/Speech/Digits/AudioMNIST/data/'\n",
    "preprocessingPipeline = PreprocessingPipeline(root, 'data.json')\n",
    "preprocessingPipeline.process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce720850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
