{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f39f487",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size:3rem;color:darkcyan\"> Train VAE model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0f9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bbf3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "def import_dataset(dataset_path):\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # split list into different np arrays\n",
    "    inputs = np.array(data['log_spectrogram'])\n",
    "    filenames = np.array(data['filenames'])\n",
    "    min_max_values = np.array(data['min_max_values'])\n",
    "    \n",
    "    # reshape to add one dimension to features for CNN\n",
    "    inputs = inputs[..., np.newaxis] \n",
    "    return inputs, filenames, min_max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "078468ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, filenames, min_max_values = import_dataset('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5cb91d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 256, 64, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape # [# inputs, # freq bins, # time frames, # 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7e346",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c592049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, \\\n",
    "BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose, \\\n",
    "Activation, Lambda\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "229289c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    \n",
    "    def __init__(self, \n",
    "                input_shape,\n",
    "                conv_filters,\n",
    "                conv_kernels,\n",
    "                conv_strides,\n",
    "                latent_space_dim):\n",
    "        \n",
    "        self.input_shape = input_shape \n",
    "        self.conv_filters = conv_filters\n",
    "        self.conv_kernels = conv_kernels\n",
    "        self.conv_strides = conv_strides\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        self.alpha = 1000000\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "        \n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "    \n",
    "    def compile(self, learning_rate = 0.0001):\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, \n",
    "                           loss = self._calculate_combined_loss,\n",
    "                           )\n",
    "    \n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train, \n",
    "                      x_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = num_epochs,\n",
    "                      shuffle = True)\n",
    "        \n",
    "    def save(self, save_folder='.'):\n",
    "        self._create_folder_if_needed(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, save_folder='.'):\n",
    "        parameters_path = os.path.join(save_folder, 'parameters.pkl')\n",
    "        with open(parameters_path, 'rb') as f:\n",
    "            parameters = pickle.load(f)\n",
    "        # make autoencoder object\n",
    "        autoencoder = VAE(*parameters)\n",
    "        # load weights\n",
    "        weights_path = os.path.join(save_folder, 'weights.h5')\n",
    "        autoencoder.model.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_representations = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_representations, latent_representations\n",
    "        \n",
    "    def _calculate_combined_loss(self,y_target, y_predicted):\n",
    "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
    "        combined_loss = self.alpha * reconstruction_loss + kl_loss\n",
    "        return combined_loss\n",
    "    \n",
    "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
    "        error = y_target - y_predicted\n",
    "        reconstruction_loss = K.mean(K.square(error), axis = [1, 2, 3])\n",
    "        return reconstruction_loss\n",
    "    \n",
    "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.log_variance - K.square(self.mu) - \n",
    "                                K.exp(self.log_variance), axis = 1)\n",
    "        return kl_loss\n",
    "    \n",
    "    def _load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "    \n",
    "    def _create_folder_if_needed(self, folder_name):\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "            \n",
    "    def _save_parameters(self, folder_name):\n",
    "        parameters = [\n",
    "            self.input_shape, \n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(folder_name, 'parameters.pkl')\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(parameters, f)\n",
    "            \n",
    "    def _save_weights(self, folder_name):\n",
    "        save_path = os.path.join(folder_name, 'weights.h5')\n",
    "        self.model.save_weights(save_path)\n",
    "        \n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder() \n",
    "        \n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        self._model_input = encoder_input\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self.encoder = Model(encoder_input, bottleneck, name = 'encoder')\n",
    "        \n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape = self.input_shape, name = 'encoder_input')\n",
    "    \n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        layer_graph = encoder_input\n",
    "        for i in range(self._num_conv_layers):\n",
    "            layer_graph = self._add_conv_layer(i, layer_graph)\n",
    "        return layer_graph\n",
    "    \n",
    "    def _add_conv_layer(self, layer_index, layer_graph):\n",
    "        # conv2D + ReLu + batch normalization\n",
    "        \n",
    "        current_layer = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters = self.conv_filters[layer_index],\n",
    "            kernel_size = self.conv_kernels[layer_index],\n",
    "            strides = self.conv_strides[layer_index],\n",
    "            padding = 'same',\n",
    "            name = f'encoder_conv_layer_{current_layer}'\n",
    "        )\n",
    "        \n",
    "        layer_graph = conv_layer(layer_graph)\n",
    "        layer_graph = ReLU(name=f'encoder_relu_{current_layer}')(layer_graph)\n",
    "        layer_graph = BatchNormalization(name=f'encoder_bn_{current_layer}')(layer_graph)\n",
    "        \n",
    "        return layer_graph\n",
    "    \n",
    "    def _add_bottleneck(self, layer_graph): \n",
    "        # save shape for decoding\n",
    "        self._shape_before_bottleneck = K.int_shape(layer_graph)[1:]\n",
    "        \n",
    "        # flatten data and add bottleneck with Gaussian sampling\n",
    "        layer_graph = Flatten()(layer_graph)\n",
    "        \n",
    "        # create two branches of dense layers, one for the mean vector, one for log variance vector:\n",
    "        self.mu = Dense(self.latent_space_dim, name = 'mu')(layer_graph)\n",
    "        self.log_variance = Dense(self.latent_space_dim, \n",
    "                                  name = 'log_variance')(layer_graph)\n",
    "        \n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape = K.shape(self.mu), \n",
    "                                      mean = 0., \n",
    "                                      stddev = 1.)\n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point\n",
    "            \n",
    "        # merge two layers (wrapping function in graph using Lambda)\n",
    "        layer_graph = Lambda(sample_point_from_normal_distribution, \n",
    "                             name = 'encoder_output')([self.mu, self.log_variance])\n",
    "        \n",
    "        return layer_graph\n",
    "    \n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name = 'decoder')\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape = self.latent_space_dim, name = 'decoder_input')\n",
    "    \n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck)\n",
    "        return Dense(num_neurons, name = 'decoder_dense')(decoder_input)\n",
    "       \n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "    \n",
    "    def _add_conv_transpose_layers(self, layer_graph):\n",
    "        for i in reversed(range(1, self._num_conv_layers)): # ignore input layer\n",
    "            layer_graph = self._add_conv_transpose_layer(i, layer_graph)\n",
    "        return layer_graph\n",
    "    \n",
    "    def _add_conv_transpose_layer(self, layer_index, layer_graph):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters = self.conv_filters[layer_index],\n",
    "            kernel_size = self.conv_kernels[layer_index],\n",
    "            strides = self.conv_strides[layer_index],\n",
    "            padding = 'same',\n",
    "            name = f'decoder_conv_transpose_layer_{layer_num}'\n",
    "        )\n",
    "        \n",
    "        layer_graph = conv_transpose_layer(layer_graph)\n",
    "        layer_graph = ReLU(name = f'decoder_ReLU_{layer_num}')(layer_graph)\n",
    "        layer_graph = BatchNormalization(name = f'decoder_bn_{layer_num}')(layer_graph)\n",
    "        \n",
    "        return layer_graph\n",
    "    \n",
    "    def _add_decoder_output(self, layer_graph):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters = 1,\n",
    "            kernel_size = self.conv_kernels[0],\n",
    "            strides = self.conv_strides[0],\n",
    "            padding = 'same',\n",
    "            name = f'decoder_conv_transpose_layer_{self._num_conv_layers}'\n",
    "        ) \n",
    "        \n",
    "        layer_graph = conv_transpose_layer(layer_graph)\n",
    "        output_layer = Activation('sigmoid', name = 'output_sigmoid_layer')(layer_graph)\n",
    "        return output_layer\n",
    "        \n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name = 'autoencoder')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd666a8",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e07d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder = VAE(\n",
    "    input_shape =  (256, 64, 1),\n",
    "    conv_filters = (512,256,64,32),\n",
    "    conv_kernels = (3,3,3,3,3),\n",
    "    conv_strides = (2,2,2,2, (2,1)),\n",
    "    latent_space_dim = 128\n",
    "    )\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, epochs)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e58c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "num_epochs = 150\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff5077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 256, 64, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " encoder_conv_layer_1 (Conv2D)  (None, 128, 32, 512  5120        ['encoder_input[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " encoder_relu_1 (ReLU)          (None, 128, 32, 512  0           ['encoder_conv_layer_1[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " encoder_bn_1 (BatchNormalizati  (None, 128, 32, 512  2048       ['encoder_relu_1[0][0]']         \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " encoder_conv_layer_2 (Conv2D)  (None, 64, 16, 256)  1179904     ['encoder_bn_1[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_2 (ReLU)          (None, 64, 16, 256)  0           ['encoder_conv_layer_2[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_2 (BatchNormalizati  (None, 64, 16, 256)  1024       ['encoder_relu_2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_3 (Conv2D)  (None, 32, 8, 64)    147520      ['encoder_bn_2[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_3 (ReLU)          (None, 32, 8, 64)    0           ['encoder_conv_layer_3[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_3 (BatchNormalizati  (None, 32, 8, 64)   256         ['encoder_relu_3[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_4 (Conv2D)  (None, 16, 4, 32)    18464       ['encoder_bn_3[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_4 (ReLU)          (None, 16, 4, 32)    0           ['encoder_conv_layer_4[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_4 (BatchNormalizati  (None, 16, 4, 32)   128         ['encoder_relu_4[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2048)         0           ['encoder_bn_4[0][0]']           \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 128)          262272      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " log_variance (Dense)           (None, 128)          262272      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " encoder_output (Lambda)        (None, 128)          0           ['mu[0][0]',                     \n",
      "                                                                  'log_variance[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,879,008\n",
      "Trainable params: 1,877,280\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 128)]             0         \n",
      "                                                                 \n",
      " decoder_dense (Dense)       (None, 2048)              264192    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 16, 4, 32)         0         \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 32, 8, 32)        9248      \n",
      " r_1 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_ReLU_1 (ReLU)       (None, 32, 8, 32)         0         \n",
      "                                                                 \n",
      " decoder_bn_1 (BatchNormaliz  (None, 32, 8, 32)        128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 64, 16, 64)       18496     \n",
      " r_2 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_ReLU_2 (ReLU)       (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " decoder_bn_2 (BatchNormaliz  (None, 64, 16, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 128, 32, 256)     147712    \n",
      " r_3 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_ReLU_3 (ReLU)       (None, 128, 32, 256)      0         \n",
      "                                                                 \n",
      " decoder_bn_3 (BatchNormaliz  (None, 128, 32, 256)     1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 256, 64, 1)       2305      \n",
      " r_4 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " output_sigmoid_layer (Activ  (None, 256, 64, 1)       0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 443,361\n",
      "Trainable params: 442,657\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 256, 64, 1)]      0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 128)               1879008   \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 256, 64, 1)        443361    \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 2,322,369\n",
      "Trainable params: 2,319,937\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "Train on 500 samples\n",
      "Epoch 1/150\n",
      "500/500 [==============================] - 46s 92ms/sample - loss: 951770051.5840\n",
      "Epoch 2/150\n",
      "500/500 [==============================] - 44s 87ms/sample - loss: 943082822.1440\n",
      "Epoch 3/150\n",
      "500/500 [==============================] - 40s 80ms/sample - loss: 937035906.0480\n",
      "Epoch 4/150\n",
      "500/500 [==============================] - 39s 78ms/sample - loss: 933842627.5840\n",
      "Epoch 5/150\n",
      "500/500 [==============================] - 40s 79ms/sample - loss: 932202521.6000\n",
      "Epoch 6/150\n",
      "500/500 [==============================] - 39s 78ms/sample - loss: 931194878.9760\n",
      "Epoch 7/150\n",
      "500/500 [==============================] - 39s 78ms/sample - loss: 930442639.3600\n",
      "Epoch 8/150\n",
      "500/500 [==============================] - 41s 81ms/sample - loss: 929973445.1200\n",
      "Epoch 9/150\n",
      "500/500 [==============================] - 40s 79ms/sample - loss: 929530373.6320\n",
      "Epoch 10/150\n",
      "500/500 [==============================] - 39s 77ms/sample - loss: 929202714.6240\n",
      "Epoch 11/150\n",
      "500/500 [==============================] - 39s 78ms/sample - loss: 928857057.7920\n",
      "Epoch 12/150\n",
      "500/500 [==============================] - 39s 78ms/sample - loss: 928533202.4320\n",
      "Epoch 13/150\n",
      "500/500 [==============================] - 39s 79ms/sample - loss: 928255378.4320\n",
      "Epoch 14/150\n",
      "500/500 [==============================] - 39s 77ms/sample - loss: 928011886.0800\n",
      "Epoch 15/150\n",
      "500/500 [==============================] - 39s 77ms/sample - loss: 927784786.9440\n",
      "Epoch 16/150\n",
      "500/500 [==============================] - 39s 79ms/sample - loss: 927624001.5360\n",
      "Epoch 17/150\n",
      "500/500 [==============================] - 40s 80ms/sample - loss: 927501017.0880\n",
      "Epoch 18/150\n",
      "500/500 [==============================] - 40s 80ms/sample - loss: 927408710.1440\n",
      "Epoch 19/150\n",
      "500/500 [==============================] - 39s 78ms/sample - loss: 927348222.4640\n",
      "Epoch 20/150\n",
      "500/500 [==============================] - 40s 80ms/sample - loss: 927304055.2960\n",
      "Epoch 21/150\n",
      "500/500 [==============================] - 43s 85ms/sample - loss: 927271451.6480\n",
      "Epoch 22/150\n",
      "500/500 [==============================] - 40s 81ms/sample - loss: 927245444.0960\n",
      "Epoch 23/150\n",
      "500/500 [==============================] - 42s 85ms/sample - loss: 927224482.8160\n",
      "Epoch 24/150\n",
      "500/500 [==============================] - 43s 86ms/sample - loss: 927206807.0400\n",
      "Epoch 25/150\n",
      "192/500 [==========>...................] - ETA: 28s - loss: 919044309.3333"
     ]
    }
   ],
   "source": [
    "autoencoder = train(inputs, learning_rate, batch_size, num_epochs)\n",
    "autoencoder.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
